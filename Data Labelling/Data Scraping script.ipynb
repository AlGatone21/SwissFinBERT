{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Thesis Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the necessary packages to scrape the data\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Pipeline Transformer - German Sentiment BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Master_Dataset_v1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GSentBERT_label\"] = \"pending\"\n",
    "df[\"GSentBERT_score\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(len(df.Text))):\n",
    "    if df.GFinBERT_label[row] == \"pending\":\n",
    "        try:\n",
    "            score = sent_pipeline(df.Text[row][:512])\n",
    "            df.loc[row, \"GFinBERT_label\"] = score[0][\"label\"]\n",
    "            df.loc[row, \"GFinBERT_score\"] = score[0][\"score\"]\n",
    "        except :\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v2.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Pipeline Transformer - German FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sent_pipeline = pipeline(\"text-classification\", model=\"scherrmann/GermanFinBert_SC_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/teamspace/studios/this_studio/Master_Tesis/Master_Dataset_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GFinBERT_label\"] = \"pending\"\n",
    "df[\"GFinBERT_score\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(len(df.Text))):\n",
    "    if df.GFinBERT_label[row] == \"pending\":\n",
    "        try:\n",
    "            score = sent_pipeline(df.Text[row][:512])\n",
    "            df.loc[row, \"GFinBERT_label\"] = score[0][\"label\"]\n",
    "            df.loc[row, \"GFinBERT_score\"] = score[0][\"score\"]\n",
    "        except :\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v3.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Pipeline Transformer - FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\",device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/teamspace/studios/this_studio/Master_Tesis/Master_Dataset_v3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FinBERT_label\"] = \"pending\"\n",
    "df[\"FinBERT_score\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(len(df.Text))):\n",
    "    if df.FinBERT_label[row] == \"pending\":\n",
    "        try:\n",
    "            score = pipe(df.Text[row][:512])\n",
    "            df.loc[row, \"FinBERT_label\"] = score[0][\"label\"]\n",
    "            df.loc[row, \"FinBERT_score\"] = score[0][\"score\"]\n",
    "        except :\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v4.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open AI ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Master_Dataset_v4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"insert your key here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GPT3_5_label\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    if df.GPT3_5_label[i] == \"pending\":\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            role = \"\"\"\n",
    "                You are a helpful financial analyst. I will provide you with a financial news article in german and I want you to read it and give me your sentiment about it.\n",
    "                    \"\"\"\n",
    "\n",
    "            instruction= \"\"\"\n",
    "            I will provide you with a financial news article in german and I want you to read it and give me your sentiment about it. You shold\n",
    "            express if the provided information is positive, negative or neutral for the swiss stock market. If you think that the information is positive\n",
    "            and the stock market will likely go up, I want your answer be BUY. If you think that the information is negative and the stock market will likely go down,\n",
    "            I want your answer be SELL. If you think that the information is neutral and the stock market will likely stay the same, I want your answer be HOLD.\n",
    "            In the case the information is not really relevant for the stock market, I want your answer to be HOLD.\n",
    "\n",
    "            I'am going to use this information to cluster the news articles and construct a weekly sentiment index for the swiss stock market.\n",
    "\n",
    "            I want your answer be exaclly one of the following options, just one word, dont add anything else:\n",
    "\n",
    "            BUY, HOLD, SELL\n",
    "                        \"\"\"\n",
    "\n",
    "            article_text = df.Text[i]\n",
    "            completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            max_tokens=2,\n",
    "            temperature=0.0,\n",
    "            messages=[{\"role\": \"system\", \"content\": role},{\"role\": \"user\", \"content\": instruction+\" \"+article_text}])\n",
    "            if completion.choices[0].message.content in [\"BUY\", \"SELL\", \"HOLD\", \"Sell\", \"Buy\", \"Hold\", \"buy\", \"sell\", \"hold\"]:\n",
    "                df.loc[i, \"GPT3_5_label\"] = completion.choices[0].message.content\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v5.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Master_Dataset_v5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gemini_label\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='insert your key here')\n",
    "\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\", generation_config=generation_config,)\n",
    "\n",
    "\n",
    "role = \"\"\"\n",
    "You are a helpful financial analyst. I will provide you with a financial news article in german and I want you to read it and give me your sentiment about it.\n",
    "        \"\"\"\n",
    "instruction= \"\"\"\n",
    "I will provide you with a financial news article in german and I want you to read it and give me your sentiment about it. You shold\n",
    "express if the provided information is positive, negative or neutral for the swiss stock market. If you think that the information is positive\n",
    "and the stock market will likely go up, I want your answer be BUY. If you think that the information is negative and the stock market will likely go down,\n",
    "I want your answer be SELL. If you think that the information is neutral and the stock market will likely stay the same, I want your answer be HOLD.\n",
    "In the case the information is not really relevant for the stock market, I want your answer to be HOLD.\n",
    "\n",
    "I'am going to use this information to cluster the news articles and construct a weekly sentiment index for the swiss stock market.\n",
    "\n",
    "I want your answer be exaclly one of the following options, just one word, dont add anything else:\n",
    "\n",
    "BUY, HOLD, SELL\n",
    "                \"\"\"\n",
    "\n",
    "for i in tqdm(range(25000, len(df.Gemini_label))):\n",
    "    if df.Gemini_label[i] == \"pending\":\n",
    "        try:  \n",
    "          article_text = df.Text[i]\n",
    "          response = model.generate_content(f'{role} \\n {instruction}\\n{article_text}')\n",
    "          if response.text in [\"BUY\", \"SELL\", \"HOLD\", \"Sell\", \"Buy\", \"Hold\", \"buy\", \"sell\", \"hold\"]:\n",
    "              df.loc[i, \"Gemini_label\"] = response.text\n",
    "          time.sleep(0.8)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.Gemini_label.isin([\"HOLD\", \"BUY\", \"SELL\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v6.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SwissFinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"AlGatone21/SwissFinBERT\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"Schweizer Aktienmarkt sinkt um 2%, die Anleger sind sehr sehr pessimistisch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Master_Dataset_v6.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SwissFinBERT_label\"] = \"pending\"\n",
    "df[\"SwissFinBERT_score\"] = \"pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(len(df.Text))):\n",
    "    if df.SwissFinBERT_label[row] == \"pending\":\n",
    "        try:\n",
    "            score = pipe(df.Text[row][:512])\n",
    "            df.loc[row, \"SwissFinBERT_label\"] = score[0][\"label\"]\n",
    "            df.loc[row, \"SwissFinBERT_score\"] = score[0][\"score\"]\n",
    "        except :\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['SwissFinBERT_label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['GFinBERT_label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Master_Dataset_v15.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Master_Dataset_v15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Date\", \"GSebtBERT_label\", \"GFinBERT_label\", \"FinBERT_label\", \"GPT3_5_label\", \"Gemini_label\", \"SwissFinBERT_label\", \"smi_nlabel_t1\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_matchings = { \"BUY\" : 2, \"HOLD\" : 1, \"SELL\" : 0, \"positive\" : 2, \"neutral\" : 1, \"negative\" : 0, \"pending\" : 1, \"Negativ\" : 0, \"Neutral\" : 1, \"Positiv\" : 2}\n",
    "\n",
    "df[\"GSebtBERT_label\"] = df[\"GSebtBERT_label\"].map(label_matchings)\n",
    "df[\"GFinBERT_label\"] = df[\"GFinBERT_label\"].map(label_matchings)\n",
    "df[\"FinBERT_label\"] = df[\"FinBERT_label\"].map(label_matchings)\n",
    "df[\"GPT3_5_label\"] = df[\"GPT3_5_label\"].map(label_matchings)\n",
    "df[\"Gemini_label\"] = df[\"Gemini_label\"].map(label_matchings)\n",
    "df[\"SwissFinBERT_label\"] = df[\"SwissFinBERT_label\"].map(label_matchings)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"GSebtBERT_label\": \"GSentBERT_label\"}, inplace=True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
